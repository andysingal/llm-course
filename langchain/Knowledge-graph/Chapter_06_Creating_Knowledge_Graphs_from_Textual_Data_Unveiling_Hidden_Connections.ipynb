{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jFmPv7qAk-h",
        "outputId": "5444cdd2-156d-4b08-8f89-6bdc6b3956d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.208 openai==0.27.8 python-dotenv pyvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdhPiWF1CbhM",
        "outputId": "3f605fe4-a6eb-43b2-b75e-abdd2fb667f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "!echo \"OPENAI_API_KEY='<OPENAI_API_KEY>'\" > .env\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XvgMXSRCeNE",
        "outputId": "78336cf0-7fdb-4511-8a5a-1184d750c395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Paris, is the capital of, France)<|>(Paris, is the most populous city of, France)<|>(Eiffel Tower, is a famous landmark in, Paris)\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
        "\n",
        "# Prompt template for knowledge triple extraction\n",
        "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
        "    \"You are a networked intelligence helping a human track knowledge triples\"\n",
        "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
        "    \" them with your knowledge stored within your weights\"\n",
        "    \" as well as that stored in a knowledge graph.\"\n",
        "    \" Extract all of the knowledge triples from the text.\"\n",
        "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
        "    \" and an object. The subject is the entity being described,\"\n",
        "    \" the predicate is the property of the subject that is being\"\n",
        "    \" described, and the object is the value of the property.\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\n\"\n",
        "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
        "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
        "    \"END OF EXAMPLE\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"I'm going to the store.\\n\\n\"\n",
        "    \"Output: NONE\\n\"\n",
        "    \"END OF EXAMPLE\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
        "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
        "    \"END OF EXAMPLE\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"{text}\"\n",
        "    \"Output:\"\n",
        ")\n",
        "\n",
        "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
        ")\n",
        "\n",
        "# Instantiate the OpenAI model\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.0)\n",
        "\n",
        "# Create an LLMChain using the knowledge triple extraction prompt\n",
        "chain = LLMChain(llm=llm, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)\n",
        "\n",
        "# Run the chain with the specified text\n",
        "text = \"The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.\"\n",
        "triples = chain.run(text)\n",
        "\n",
        "print(triples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17DGISoLDkCt",
        "outputId": "99c02cbb-050e-408f-cb86-810ae56f74e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['(Paris, is the capital of, France)', '(Paris, is the most populous city of, France)', '(Eiffel Tower, is a famous landmark in, Paris)']\n"
          ]
        }
      ],
      "source": [
        "def parse_triples(response, delimiter=KG_TRIPLE_DELIMITER):\n",
        "    if not response:\n",
        "        return []\n",
        "    return response.split(delimiter)\n",
        "\n",
        "triples_list = parse_triples(triples)\n",
        "\n",
        "# Print the extracted relation triplets\n",
        "print(triples_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "l93_tobPEAvs",
        "outputId": "6a3bf1ad-bbed-48ae-a497-98c93bd9fb90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "knowledge_graph.html\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600px\"\n",
              "            src=\"knowledge_graph.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7eff48495960>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyvis.network import Network\n",
        "import networkx as nx\n",
        "\n",
        "# Create a NetworkX graph from the extracted relation triplets\n",
        "def create_graph_from_triplets(triplets):\n",
        "    G = nx.DiGraph()\n",
        "    for triplet in triplets:\n",
        "        subject, predicate, obj = triplet.strip().split(',')\n",
        "        G.add_edge(subject.strip(), obj.strip(), label=predicate.strip())\n",
        "    return G\n",
        "\n",
        "# Convert the NetworkX graph to a PyVis network\n",
        "def nx_to_pyvis(networkx_graph):\n",
        "    pyvis_graph = Network(notebook=True, cdn_resources='remote')\n",
        "    for node in networkx_graph.nodes():\n",
        "        pyvis_graph.add_node(node)\n",
        "    for edge in networkx_graph.edges(data=True):\n",
        "        pyvis_graph.add_edge(edge[0], edge[1], label=edge[2][\"label\"])\n",
        "    return pyvis_graph\n",
        "\n",
        "triplets = [t.strip() for t in triples_list if t.strip()]\n",
        "graph = create_graph_from_triplets(triplets)\n",
        "pyvis_network = nx_to_pyvis(graph)\n",
        "\n",
        "# Customize the appearance of the graph\n",
        "pyvis_network.toggle_hide_edges_on_drag(True)\n",
        "pyvis_network.toggle_physics(False)\n",
        "pyvis_network.set_edge_smooth('discrete')\n",
        "\n",
        "# Show the interactive knowledge graph visualization\n",
        "pyvis_network.show(\"knowledge_graph.html\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}