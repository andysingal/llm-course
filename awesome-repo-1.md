![autoagent-intro](https://github.com/user-attachments/assets/1d315c79-8d75-4af8-abee-945334f194e8)[llamaduo](https://github.com/deep-diver/llamaduo/blob/main/notebooks/Multi_Task_Comparisons.ipynb)

[chat-circuit](https://github.com/namuan/chat-circuit)

[repo2txt](https://github.com/abinthomasonline/repo2txt)

***[Deepgit](https://github.com/zamalali/DeepGit/tree/main)

DeepGit is an advanced, Langgraph-based agentic workflow designed to perform deep research across GitHub repositories. It intelligently searches, analyzes, and ranks repositories based on user intentâ€”even uncovering less-known but highly relevant tools. DeepGit infuses hybrid dense retrieval with advanced cross-encoder re-ranking and comprehensive activity analysis into a unified, open-source platform for intelligent repository discovery

[goose](https://github.com/block/goose)
goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - autonomously.

[AutoAgent](https://github.com/HKUDS/AutoAgent)

Welcome to AutoAgent! AutoAgent is a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone.

[agentic-doc](https://github.com/landing-ai/agentic-doc)
The LandingAI Agentic Document Extraction API pulls structured data out of visually complex documentsâ€”think tables, pictures, and chartsâ€”and returns a hierarchical JSON with exact element locations.

This Python library wraps that API to provide:

- Longâ€‘document support â€“ process 100+ page PDFs in a single call
- Autoâ€‘retry / paging â€“ handles concurrency, timeâ€‘outs, and rate limits
- Helper utilities â€“ boundingâ€‘box snippets, visual debuggers, and more

[ai-agent-smart-assist](https://github.com/raminmohammadi/ai-agent-smart-assist)
This project is my own AI agent powered by LangChain. It's built to help with:

ðŸ§  Classifying text and routing it to the right logic
ðŸ“š Adding files to a searchable knowledge base
ðŸ¤– Asking questions and getting answers from what Iâ€™ve uploaded

[What is llm.pdf?](https://github.com/EvanZhouDev/llm.pdf)

This is a proof-of-concept project, showing that it's possible to run an entire Large Language Model in nothing but a PDF file.

It uses Emscripten to compile llama.cpp into asm.js, which can then be run in the PDF using an old PDF JS injection.

Combined with embedding the entire LLM file into the PDF with base64, we are able to run LLM inference in nothing but a PDF.

<img width="772" alt="Screenshot 2024-09-04 at 10 17 34â€¯PM" src="https://github.com/user-attachments/assets/e6aa4606-feb3-4521-9409-5322749535ac">
