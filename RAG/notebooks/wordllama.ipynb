{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMrfBoE6sAuK",
        "outputId": "e3cf72c6-c222-4917-d0cb-ac07db09b92e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordllama\n",
            "  Downloading wordllama-0.2.6.post2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from wordllama) (1.26.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from wordllama) (0.4.5)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from wordllama) (0.19.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from wordllama) (0.10.2)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from wordllama) (2.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wordllama) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->wordllama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->wordllama) (2.23.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->wordllama) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wordllama) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wordllama) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wordllama) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wordllama) (2024.8.30)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->wordllama) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->wordllama) (4.66.5)\n",
            "Downloading wordllama-0.2.6.post2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wordllama\n",
            "Successfully installed wordllama-0.2.6.post2\n"
          ]
        }
      ],
      "source": [
        "!pip install wordllama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from wordllama import WordLlama\n",
        "\n",
        "# Load the default WordLlama model\n",
        "wl = WordLlama.load()\n",
        "\n",
        "# Calculate similarity between two sentences\n",
        "similarity_score = wl.similarity(\"i went to the car\", \"i went to the pawn shop\")\n",
        "print(similarity_score)  # Output: 0.06641249096796882\n",
        "\n",
        "# Rank documents based on their similarity to a query\n",
        "query = \"i went to the car\"\n",
        "candidates = [\"i went to the park\", \"i went to the shop\", \"i went to the truck\", \"i went to the vehicle\"]\n",
        "ranked_docs = wl.rank(query, candidates)\n",
        "print(ranked_docs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiZU0zSHsCwK",
        "outputId": "eddfec18-5f21-4f14-f48f-e4752ac1c9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06641249358654022\n",
            "[('i went to the vehicle', 0.744164764881134), ('i went to the truck', 0.28326916694641113), ('i went to the shop', 0.1973281353712082), ('i went to the park', 0.1510140299797058)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from wordllama import WordLlama\n",
        "\n",
        "# Load pre-trained embeddings\n",
        "# truncate dimension to 64\n",
        "wl = WordLlama.load(trunc_dim=64)\n",
        "\n",
        "# Embed text\n",
        "embeddings = wl.embed([\"the quick brown fox jumps over the lazy dog\", \"and all that jazz\"])\n",
        "print(embeddings.shape)  # (2, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqtz9IKMsLng",
        "outputId": "b9a4df18-b86b-46a4-bbbb-c4f4f51680b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "862iEskssj0o",
        "outputId": "eb74cb31-58c4-4f46-d9f1-fa926bf5f3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.12470592, -0.07770053,  0.02884188,  0.21934648,  0.18028675,\n",
              "        -0.12956376, -0.04828436,  0.41509733,  0.07201316,  0.13917126,\n",
              "         0.0855602 ,  0.12068315,  0.12699752,  0.11927379,  0.00974343,\n",
              "        -0.564209  , -0.1578487 ,  0.03860474, -0.07334492, -0.26644066,\n",
              "        -0.5641868 , -0.32762977, -0.38049594,  0.21294056,  0.08007257,\n",
              "         0.16110507, -0.00196422,  0.3599271 ,  0.0900435 ,  0.17322887,\n",
              "         0.29006264, -0.29262888,  0.41510564,  0.15712148, -0.02885853,\n",
              "        -0.11202171,  0.06890869, -0.03536294, -0.06598455,  0.24811624,\n",
              "        -0.20313574, -0.30398142,  0.07795299, -0.42450505,  0.10664229,\n",
              "         0.7530911 ,  0.02276056,  0.12312213, -0.3221824 ,  0.15558554,\n",
              "         0.29816782, -0.02808033, -0.05978116,  0.20450106, -0.4262626 ,\n",
              "        -0.14082475,  0.22328836, -0.3291959 , -0.18767756, -0.29354027,\n",
              "        -0.5189202 , -0.4972867 , -0.12053888,  0.11252386],\n",
              "       [-0.06514788,  0.45723152,  0.11624908, -0.07243347, -0.12939453,\n",
              "         0.02727509,  0.04292297, -0.5540161 , -0.2977085 , -0.0976944 ,\n",
              "         0.08885193,  0.5070801 , -0.1783905 ,  0.13960266, -0.5609665 ,\n",
              "         0.23020935,  0.20321655, -0.28567505,  0.4851532 , -0.13973999,\n",
              "        -0.30326557, -0.3094902 ,  0.48687744, -0.04442406,  0.07878876,\n",
              "         0.16853333,  0.95513725, -0.1914711 , -0.16343689, -0.5366764 ,\n",
              "        -0.50642157,  0.6895752 , -0.11251068,  0.4660473 ,  0.95861745,\n",
              "         0.30542374, -0.31946564, -0.12031555, -0.26194763, -0.17658997,\n",
              "         0.41872835,  0.40130615,  0.02680206, -0.0446167 , -0.07314682,\n",
              "         0.25097656,  0.9412174 , -0.04864883, -0.16801453,  0.12799454,\n",
              "         0.12521744,  0.10856628, -0.46917725, -0.13832474, -0.30282307,\n",
              "         0.28735733,  0.23719788, -0.46734238,  0.15576363,  0.03568649,\n",
              "        -0.28373718, -0.35864258, -0.7837    ,  0.46481323]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary embeddings are packed into uint64\n",
        "# 64-dims => array of 1x uint64\n",
        "wl = WordLlama.load(trunc_dim=64, binary=True)  # this will download the binary model from huggingface\n",
        "wl.embed(\"I went to the car\") # Output: array([[3029168427562626]], dtype=uint64)\n",
        "\n",
        "# load binary trained model trained with straight through estimator\n",
        "wl = WordLlama.load(dim=1024, binary=True)\n",
        "\n",
        "# Uses the hamming similarity to binarize\n",
        "similarity_score = wl.similarity(\"i went to the car\", \"i went to the pawn shop\")\n",
        "print(similarity_score)  # Output: 0.57421875\n",
        "\n",
        "ranked_docs = wl.rank(\"i went to the car\", [\"van\", \"car\"])\n",
        "print(ranked_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXp8mOyfsl5x",
        "outputId": "50dc9b16-0166-407e-9a72-c6840e7e78b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06640625\n",
            "[('car', 0.677734375), ('van', 0.203125)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "sentences=[]\n",
        "urls = [\n",
        "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
        "]\n",
        "# each of these dataset have the same structure, so we loop through each creating our sentences data\n",
        "for url in urls:\n",
        "    res = requests.get(url)\n",
        "    # extract to dataframe\n",
        "    data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, on_bad_lines='warn')\n",
        "    # add to columns 1 and 2 to sentences list\n",
        "    sentences.extend(data[1].tolist())\n",
        "    sentences.extend(data[2].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zCPSCj-szXu",
        "outputId": "1ac62e8f-53a3-49fa-dffa-70e636a73590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 191: expected 3 fields, saw 4\n",
            "Skipping line 206: expected 3 fields, saw 4\n",
            "Skipping line 295: expected 3 fields, saw 4\n",
            "Skipping line 695: expected 3 fields, saw 4\n",
            "Skipping line 699: expected 3 fields, saw 4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [word for word in list(set(sentences)) if type(word) is str]\n",
        "print(len(set(sentences)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw_Y-SlOtxA7",
        "outputId": "278ed70f-9f6b-4cce-87ed-a7a2a9fb3e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihFM_Jbqt-uf",
        "outputId": "e666db5f-2f53-4ee7-d727-2e2304a430b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Prairie dogs sold as exotic pets are believed to have been infected in an Illinois pet shop by a Gambian giant rat imported from Africa.',\n",
              " 'Dennehy, who transferred to Baylor last year after getting kicked off the University of New Mexico Lobos for temper tantrums, had begun to read the Bible daily.',\n",
              " 'A soldier was killed Monday and another wounded when their convoy was ambushed in northern Iraq.',\n",
              " 'Redman has allowed two earned runs or less in six of his nine starts.',\n",
              " 'The government recently shelved peace talks with the MILF, being brokered by Malaysia, after a string of attacks, including three bombings, on Mindanao.',\n",
              " 'The recent turnaround in the stock market and an easing in unemployment claims should keep consumer expectations at current levels and may signal more favorable economic times ahead.',\n",
              " \"The 27-year-old rapper's attorney in the civil matter, Mark Gann, did not return calls for comment.\",\n",
              " 'Volume came to 439.66 million shares, below 450.39 million at the same point Wednesday.',\n",
              " 'It has sought observer status for seven years, but was again rebuffed May 19 at the annual WHO conference in Geneva.',\n",
              " 'Talabani told him Iraqi leaders would \"need U.N. assistance and advice in implementing the new decisions which have been taken\" on organising an interim Iraqi government by June.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "SSKmdk_DuE7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore():\n",
        "\n",
        "    def __init__(self, dim = 1024, binary=False):\n",
        "        self.embeds = {}\n",
        "        self.embedding_model =  WordLlama.load(dim=dim, binary=binary)\n",
        "    def get(self, text):\n",
        "        return self.embeds[text]\n",
        "\n",
        "    def add(self, docs):\n",
        "        embeds = self.embedding_model.embed(docs)\n",
        "        self.docs = docs\n",
        "        self.vectors = embeds\n",
        "\n",
        "    def query(self, text, num_results=10):\n",
        "        query_embed = self.embedding_model.embed(text)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        scores = self.embedding_model.vector_similarity(query_embed[0], self.vectors)\n",
        "        scores = scores.squeeze()\n",
        "        similarities = list(zip(self.docs, scores.tolist()))\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "        results = similarities[:num_results]\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "NaKpzVZKuIvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = VectorStore()"
      ],
      "metadata": {
        "id": "VSzw04j0uW1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.add(sentences)"
      ],
      "metadata": {
        "id": "EDhtSLa2vavH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.query('football')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isTfUFbXvb_i",
        "outputId": "dd0d903c-e6fc-400b-c00f-9f840f3fa5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The pressure may well rise on Thursday, with national coverage of the final round planned by ESPN, the cable sports network.',\n",
              "  0.2862741947174072),\n",
              " ('Stanford (46-15) plays South Carolina (44-20) today in a first-round game at Rosenblatt Stadium in Omaha, Neb.',\n",
              "  0.23061472177505493),\n",
              " ('That is up from $1.14 billion during the same quarter last year.',\n",
              "  0.1976434588432312),\n",
              " (\"Moore of Alabama says he will appeal his case to the nation's highest court.\",\n",
              "  0.18732286989688873),\n",
              " ('The pressure will intensify today, with national coverage of the final round planned by ESPN and words that are even more difficult.',\n",
              "  0.1754290759563446),\n",
              " ('Stanford (51-17) and Rice (57-12) will play for the national championship tonight.',\n",
              "  0.17530187964439392),\n",
              " ('The charges of espionage and aiding the enemy can carry the death penalty.',\n",
              "  0.16965657472610474),\n",
              " ('The Dodgers won their sixth consecutive game their longest win streak since 2001 as they edged Colorado, 3-2, Wednesday in front of a crowd of 25,332 at Dodger Stadium.',\n",
              "  0.16102729737758636),\n",
              " ('Board Chancellor Robert Bennett declined to comment on personnel matters Tuesday.',\n",
              "  0.15925633907318115),\n",
              " ('The only other person who had not been accounted for Sunday was a man from Fort Worth, Texas.',\n",
              "  0.15717457234859467)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.query('what are the violations', num_results=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb0SimXMvdoP",
        "outputId": "fd75bcf4-d6a0-4bc4-dc51-a70b627f424e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The federal courts have ruled that the monument violates the constitutional ban against state-established religion.',\n",
              "  0.39459460973739624),\n",
              " ('In that case, the court held that the city of Cincinnati had violated the First Amendment in banning, in the interest of aesthetics, only the advertising pamphlets.',\n",
              "  0.3732220530509949),\n",
              " ('In that case, the court held that Cincinnati had violated the First Amendment in banning only the advertising pamphlets in the interest of aesthetics.',\n",
              "  0.3661629557609558),\n",
              " ('Lay had argued that handing over the documents would be a violation of his Fifth Amendment rights against self-incrimination.',\n",
              "  0.3621053993701935),\n",
              " ('Under the law, telemarketers who call numbers on the list can be fined up to $11,000 for each violation.',\n",
              "  0.35536259412765503)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.query('tropical storm', num_results=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlThrb_1viyr",
        "outputId": "69c33b18-ad0e-430c-b4fe-150068cc8089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A tropical storm rapidly developed in the Gulf of Mexico on Sunday and could have hurricane-force winds when it hits land somewhere along the Louisiana coast Monday night.',\n",
              "  0.6678519248962402),\n",
              " ('A tropical storm rapidly developed in the Gulf of Mexico Sunday and was expected to hit somewhere along the Texas or Louisiana coasts by Monday night.',\n",
              "  0.5823907852172852),\n",
              " ('Crews worked to install a new culvert and prepare the highway so motorists could use the eastbound lanes for travel as storm clouds threatened to dump more rain.',\n",
              "  0.3848031461238861),\n",
              " (\"The heatwave was due to a mass of hot, dry air from the southeast, said Mario Almeida of Portugal's weather service.\",\n",
              "  0.31797584891319275),\n",
              " ('The weather service reported maximum sustained winds of nearly 105 miles an hour with stronger gusts.',\n",
              "  0.2692662179470062)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjxrDTnCw_KD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}