{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a5a74d",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this notebook, we will test out [Microsoft's Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct) with the [custom inference server with hugging face transformers library](app/server.py) in SAP AI Core. Enhance [btp-generative-ai-hub-use-cases/01-social-media-citizen-reporting](https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/tree/main/01-social-media-citizen-reporting) with Vision capability powered by the Phi-3-vision models, in which the issues of public facilities reported by citizen can be automatically analyzed by the Vision API with its image. <br/><br/>\n",
    "\n",
    "In addition, You can also run another transformer-based open-source LLM on [Hugging Face](https://huggingface.co), like [microsoft/Phi-3-medium-128k-instruct](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct) etc.\n",
    "\n",
    "### Prerequisites\n",
    "Before running this notebook, please assure you have performed the [Prerequisites](../../README.md) and [01-deployment.ipynb](01-deployment.ipynb). As a result, a deployment of transformer scenario is running in SAP AI Core.<br/><br/>\n",
    "\n",
    "If the configuration and deployment are created through SAP AI Launchpad, please manually update the configuration_id and deployment_id in [env.json](env.json)\n",
    "```json\n",
    "{\n",
    "    \"configuration_id\": \"<YOUR_CONFIGURATION_ID_OF_TRANSFORMER_SCENARIO>\",\n",
    "    \"deployment_id\": \"<YOUR_DEPLOYMENT_ID_BASED_ON_CONFIG_ABOVE>\"\n",
    "}\n",
    "```\n",
    "\n",
    "### The high-level flow:\n",
    "\n",
    "- Load configurations info\n",
    "- Connect to SAP AI Core via SDK\n",
    "- Check the status and logs of the deployment\n",
    "- Pull model from ollama model repository through API\n",
    "- Inference the model with OpenAI-compatible chat completion API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55bd7b",
   "metadata": {},
   "source": [
    "#### 1.Load config info\n",
    "\n",
    "- resource_group loaded from [config.json](../config.json)\n",
    "- deployment_id(created in 01-deployment.ipynb) loaded [env.json](env.json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f1e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from ai_api_client_sdk.ai_api_v2_client import AIAPIV2Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eee26b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment id:  d2156e8d87b824ad  resource group:  oss-llm\n"
     ]
    }
   ],
   "source": [
    "# Please replace the configurations below.\n",
    "# config_id: The target configuration to create the deployment. Please create the configuration first.\n",
    "with open(\"../config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "with open(\"./env.json\") as f:\n",
    "    env = json.load(f)\n",
    "\n",
    "deployment_id = env[\"deployment_id\"]\n",
    "resource_group = config.get(\"resource_group\", \"default\")\n",
    "print(\"deployment id: \", deployment_id, \" resource group: \", resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd694c3",
   "metadata": {},
   "source": [
    "#### 2.Initiate connection to SAP AI Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4cc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_sk = config[\"ai_core_service_key\"]\n",
    "base_url = aic_sk[\"serviceurls\"][\"AI_API_URL\"] + \"/v2/lm\"\n",
    "ai_api_client = AIAPIV2Client(\n",
    "    base_url=base_url,\n",
    "    auth_url=aic_sk[\"url\"] + \"/oauth/token\",\n",
    "    client_id=aic_sk[\"clientid\"],\n",
    "    client_secret=aic_sk[\"clientsecret\"],\n",
    "    resource_group=resource_group,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffb297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = ai_api_client.rest_client.get_token()\n",
    "headers = {\n",
    "    \"Authorization\": token,\n",
    "    \"ai-resource-group\": resource_group,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7b416",
   "metadata": {},
   "source": [
    "#### 3.Check the deployment status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check deployment status before inference request\n",
    "deployment_url = f\"{base_url}/deployments/{deployment_id}\"\n",
    "response = requests.get(url=deployment_url, headers=headers)\n",
    "resp = response.json()\n",
    "status = resp[\"status\"]\n",
    "\n",
    "deployment_log_url = (\n",
    "    f\"{base_url}/deployments/{deployment_id}/logs?start=2024-03-25T01:35:58\"\n",
    ")\n",
    "\n",
    "if status == \"RUNNING\":\n",
    "    print(f\"Deployment-{deployment_id} is running. Ready for inference request\")\n",
    "else:\n",
    "    print(\n",
    "        f\"Deployment-{deployment_id} status: {status}. Not yet ready for inference request\"\n",
    "    )\n",
    "    # retrieve deployment logs\n",
    "    # {{apiurl}}/v2/lm/deployments/{{deploymentid}}/logs.\n",
    "    response = requests.get(url=deployment_log_url, headers=headers)\n",
    "    print(\"Deployment Logs:\\n\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c8e58d",
   "metadata": {},
   "source": [
    "#### 4.Prepare for inferencing\n",
    "\n",
    "We'll use [Microsoft's Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86047d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"microsoft/Phi-3-vision-128k-instruct\"\n",
    "deployment = ai_api_client.deployment.get(deployment_id)\n",
    "\n",
    "inference_base_url = f\"{deployment.deployment_url}\"\n",
    "openai_chat_api_endpoint = f\"{inference_base_url}/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7d13c",
   "metadata": {},
   "source": [
    "#### 5.Inference OpenAI-like chat completion API for Vision\n",
    "\n",
    "In the following samples, we'll enhance [btp-generative-ai-hub-use-cases/01-social-media-citizen-reporting](https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/tree/main/01-social-media-citizen-reporting) with Vision capability powered by the Phi-3-vision model serving with the [custom inference server with hugging face transformers library](app/server.py) in SAP AI Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364cf04",
   "metadata": {},
   "source": [
    "##### 5.1 Vision Sample#1: Describe the image (a cracked bridge)\n",
    "\n",
    "Let's start with a simple question to ask the model to describe the image in nature language.<br/><br/>\n",
    "Display the sample image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d758359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/SAP-samples/btp-generative-ai-hub-use-cases/main/10-byom-oss-llm-ai-core/resources/10-bridge-crack.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# URL of the image\n",
    "# To replace an image with raw image url\n",
    "image_url = \"https://raw.githubusercontent.com/SAP-samples/btp-generative-ai-hub-use-cases/main/10-byom-oss-llm-ai-core/resources/10-bridge-crack.png\"\n",
    "\n",
    "# Display the image\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c3a8574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {\"id\":\"1718385804\",\"object\":\"chat.completion\",\"created\":1718385804,\"model\":\"microsoft/Phi-3-vision-128k-instruct\",\"system_fingerprint\":\"fp_44709d6fcb\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The image shows a large concrete overpass with a van parked underneath it. The overpass has pillars supporting it, and there is graffiti on one of the pillars. Below the overpass, there are buildings and a parking lot with various vehicles. A puddle of water is visible on the ground.\"},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":1,\"total_tokens\":1}}\n"
     ]
    }
   ],
   "source": [
    "user_msg = \"What is in the image?\"\n",
    "#image_url = \"https://raw.githubusercontent.com/SAP-samples/btp-generative-ai-hub-use-cases/main/10-byom-oss-llm-ai-core/resources/11-dirty-street.jpg\"\n",
    "json_data = {\n",
    "    \"model\": model,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_msg},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.7,\n",
    "    \"do_sample\": \"True\"\n",
    "}\n",
    "\n",
    "response = requests.post(url=openai_chat_api_endpoint, headers=headers, json=json_data)\n",
    "print(\"Result:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8e91e",
   "metadata": {},
   "source": [
    "##### 5.2 Vision Sample#2: Public Facilities Issue Spotter for [Citizen Reporting use case](https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/tree/main/01-social-media-citizen-reporting) (e.g. Bridge Damage)\n",
    "\n",
    "In next sample, we'll ask the [Microsoft's Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct) to be an Assistant of Public Facilities Issue Spotter for city council.\n",
    "Responsible for analyzing images reported by citizens through a mobile app to identify issues related to public facilities. <br/>\n",
    "Here are the tasks: <br/>\n",
    "\n",
    "- 1.Analyze images reported by citizens through a mobile app to identify issues related to public facilities. If no issue identified, go to step 5, otherwise continue with next steps\n",
    "- 2.Extract photographic date and location information from images for accurate documentation.\n",
    "- 3.Categorize identified issues based on predefined categories (e.g., infrastructure damage, cleanliness, safety hazards).\n",
    "- 4.Assess the severity and priority of identified issues to determine appropriate action plans.\n",
    "- 5.Output with JSON schema in triple quote as below:\n",
    "\n",
    "```json\n",
    "{ \"issue_identified\": \"{{true or false}}\",\n",
    "#below section only output when there is an issue identified\n",
    "\"title\": \"{{A title about the issue less than 100 characters}}\",\n",
    "\"description\": \"{{A short description about the issue less than 300 characters}}\",\n",
    "\"photo_date\": \"{{Extracted photographic date from its metadata in yyyy-mm-dd:hh:mm:ss format}}\",\n",
    "\"longitude\": \"{{Extracted the longitude of photographic location from its metadata. Output -1 if fails to extract location info from image}}\",\n",
    "\"latitude\": \"{{Extracted the latitude of photographic location from its metadata. Output -1 if fails to extract location info from image}}\",\n",
    "\"category\": \"{{Identified category: 01-Infrastructure Damage, 02-Cleanliness, 03-Safety Hazards, 04-Duplicated}}\",\n",
    "\"priority\": \"{{Identified priority: 01-Very High, 02-High, 03-Medium, 04-Low}}\",\n",
    "\"suggested_action\": \"{{01-Immediate Attendance, 02-Schedule Inspection, 03-Schedule Service, 04-Refer to similar issue}}\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daa01c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {\"id\":\"1718385918\",\"object\":\"chat.completion\",\"created\":1718385918,\"model\":\"microsoft/Phi-3-vision-128k-instruct\",\"system_fingerprint\":\"fp_44709d6fcb\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"{\\n  \\\"issue_identified\\\": true,\\n  \\\"title\\\": \\\"Damage to Concrete\\\",\\n  \\\"description\\\": \\\"The concrete under the bridge appears to be cracked and damaged, posing a potential safety hazard.\\\",\\n  \\\"photo_date\\\": \\\"2023-04-01 10:30:00\\\",\\n  \\\"longitude\\\": -85.3687,\\n  \\\"latitude\\\": 43.8500,\\n  \\\"category\\\": 01,\\n  \\\"priority\\\": 01,\\n  \\\"suggested_action\\\": \\\"Immediate Attendance\\\"\\n}\"},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":1,\"total_tokens\":1}}\n"
     ]
    }
   ],
   "source": [
    "user_msg = 'You are a helpful Assistant of Public Facilities Issue Spotter for city council.\\\n",
    "Responsible for analyzing images reported by citizens through a mobile app to identify issues related to public facilities. \\\n",
    "Here are your tasks:\\\n",
    "1.Analyze images reported by citizens through a mobile app to identify issues related to public facilities. \\\n",
    "If no issue identified, go to step 5, otherwise continue with next steps \\\n",
    "2.Extract photographic date and location information from images for accurate documentation. \\\n",
    "3.Categorize identified issues based on predefined categories (e.g., infrastructure damage, cleanliness, safety hazards).\\\n",
    "4.Assess the severity and priority of identified issues to determine appropriate action plans. \\\n",
    "5.Output with JSON schema in triple quote as below:\\\n",
    "\"\"\" \\\n",
    "{ \"issue_identified\": \"{{true or false}}\", \\\n",
    "#below section only output when there is an issue identified\\\n",
    "\"title\": \"{{A short title about the issue}}\", \\\n",
    "\"description\": \"{{A detail description about the issue}}\", \\\n",
    "\"photo_date\": \"{{Extracted photographic date from its metadata in yyyy-mm-dd:hh:mm:ss format. Leave it blank if no metadata found in it.}}\", \\\n",
    "\"longitude\": \"{{Extracted longitude of photographic location from its metadata. Do not make up any number. Output -1 if fails to extract location info from image}}\",\\\n",
    "\"latitude\": \"{{Extracted latitude of photographic location from its metadata. Do not make up any number. Output -1 if fails to extract location info from image}}\",\\\n",
    "\"category\": \"{{Identified category: 01-Infrastructure Damage, 02-Cleanliness, 03-Safety Hazards, 04-Duplicated}}\",\\\n",
    "\"priority\": \"{{Suggested Priority: 01-Very High, 02-High, 03-Medium, 04-Low}}\",\\\n",
    "\"suggested_action\": \"{{01-Immediate Attendance, 02-Schedule Inspection, 03-Schedule Service, 04-Refer to similar issue }}\"\\\n",
    "} \\\n",
    "\"\"\"\\\n",
    "'\n",
    "\n",
    "json_data = {\n",
    "    \"model\": model,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_msg},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_new_tokens\": 1000,\n",
    "    \"temperature\": 0.7,\n",
    "    \"do_sample\": \"True\"\n",
    "}\n",
    "\n",
    "response = requests.post(url=openai_chat_api_endpoint, headers=headers, json=json_data)\n",
    "print(\"Result:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653579a0",
   "metadata": {},
   "source": [
    "##### 5.3 Vision Sample#3: Describe the image (e.g. a littered street)\n",
    "\n",
    "Let's continue with another sample image about a littered street, asking the model to describe the image in nature language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17262c59",
   "metadata": {},
   "source": [
    "Display the sample image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac73b867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/SAP-samples/btp-generative-ai-hub-use-cases/main/10-byom-oss-llm-ai-core/resources/11-dirty-street.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_url = \"https://raw.githubusercontent.com/SAP-samples/btp-generative-ai-hub-use-cases/main/10-byom-oss-llm-ai-core/resources/11-dirty-street.jpg\"\n",
    "# Display the image\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239604d",
   "metadata": {},
   "source": [
    "Let's ask it to spots on the public facility issue in the image, and Describe the issue in detail if any.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "466e14c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {\"id\":\"1718385980\",\"object\":\"chat.completion\",\"created\":1718385980,\"model\":\"microsoft/Phi-3-vision-128k-instruct\",\"system_fingerprint\":\"fp_44709d6fcb\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"There are no visible spots on the public facility in the image that can be described in detail.\"},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":1,\"total_tokens\":1}}\n"
     ]
    }
   ],
   "source": [
    "user_msg = \"Spots on the public facility issue in the image, and Describe the issue in detail if any\"\n",
    "\n",
    "json_data = {\n",
    "    \"model\": model,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_msg},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.7,\n",
    "    \"do_sample\": \"True\"\n",
    "}\n",
    "\n",
    "response = requests.post(url=openai_chat_api_endpoint, headers=headers, json=json_data)\n",
    "print(\"Result:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae67404",
   "metadata": {},
   "source": [
    "##### 5.4 Vision Sample#4: Public Facilities Issue Spotter for [Citizen Reporting use case](https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/tree/main/01-social-media-citizen-reporting) (e.g. a dirty street)\n",
    "\n",
    "In next sample, we'll ask the [Microsoft's Phi-3-vision-128k-instruct](https://huggingface.co/microsoft/Phi-3-small-128k-instruct) to be an Assistant of Public Facilities Issue Spotter for city council.\n",
    "Responsible for analyzing images reported by citizens through a mobile app to identify issues related to public facilities. <br/>\n",
    "Here are the tasks: <br/>\n",
    "\n",
    "- 1.Analyze images reported by citizens through a mobile app to identify issues related to public facilities. If no issue identified, go to step 5, otherwise continue with next steps\n",
    "- 2.Extract photographic date and location information from images for accurate documentation.\n",
    "- 3.Categorize identified issues based on predefined categories (e.g., infrastructure damage, cleanliness, safety hazards).\n",
    "- 4.Assess the severity and priority of identified issues to determine appropriate action plans.\n",
    "- 5.Output with JSON schema in triple quote as below:\n",
    "\n",
    "```json\n",
    "{ \"issue_identified\": \"{{true or false}}\",\n",
    "#below section only output when there is an issue identified\n",
    "\"title\": \"{{A title about the issue less than 100 characters}}\",\n",
    "\"description\": \"{{A short description about the issue less than 300 characters}}\",\n",
    "\"photo_date\": \"{{Extracted photographic date from its metadata in yyyy-mm-dd:hh:mm:ss format}}\",\n",
    "\"longitude\": \"{{Extracted the longitude of photographic location from its metadata. Output -1 if fails to extract location info from image}}\",\n",
    "\"latitude\": \"{{Extracted the latitude of photographic location from its metadata. Output -1 if fails to extract location info from image}}\",\n",
    "\"category\": \"{{Identified category: 01-Infrastructure Damage, 02-Cleanliness, 03-Safety Hazards, 04-Duplicated}}\",\n",
    "\"priority\": \"{{Identified priority: 01-Very High, 02-High, 03-Medium, 04-Low}}\",\n",
    "\"suggested_action\": \"{{01-Immediate Attendance, 02-Schedule Inspection, 03-Schedule Service, 04-Refer to similar issue}}\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6bc84c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {\"id\":\"1718386052\",\"object\":\"chat.completion\",\"created\":1718386052,\"model\":\"microsoft/Phi-3-vision-128k-instruct\",\"system_fingerprint\":\"fp_44709d6fcb\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"```json\\n\\n{\\n\\n  \\\"issue_identified\\\": true,\\n\\n  \\\"title\\\": \\\"Litter on Roadway\\\",\\n\\n  \\\"description\\\": \\\"A street with litter on the ground and along the side of the road.\\\",\\n\\n  \\\"photo_date\\\": \\\"2023-04-01 13:47:35\\\",\\n\\n  \\\"longitude\\\": \\\"123.456789\\\",\\n\\n  \\\"latitude\\\": \\\"45.678910\\\",\\n\\n  \\\"category\\\": \\\"01-Infrastructure Damage\\\",\\n\\n  \\\"priority\\\": \\\"01-Very High\\\",\\n\\n  \\\"suggested_action\\\": \\\"01-Immediate Attendance\\\"\\n\\n}\\n\\n```\"},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":1,\"total_tokens\":1}}\n"
     ]
    }
   ],
   "source": [
    "user_msg = 'You are a helpful Assistant of Public Facilities Issue Spotter for city council.\\\n",
    "Responsible for analyzing images reported by citizens through a mobile app to identify issues related to public facilities. \\\n",
    "Here are your tasks:\\\n",
    "1.Analyze images reported by citizens through a mobile app to identify issues related to public facilities. \\\n",
    "If no issue identified, go to step 5, otherwise continue with next steps \\\n",
    "2.Extract photographic date and location information from images for accurate documentation. \\\n",
    "3.Categorize identified issues based on predefined categories (e.g., infrastructure damage, cleanliness, safety hazards).\\\n",
    "4.Assess the severity and priority of identified issues to determine appropriate action plans. \\\n",
    "5.Output with JSON schema in triple quote as below:\\\n",
    "\"\"\" \\\n",
    "{ \"issue_identified\": \"{{true or false}}\", \\\n",
    "#below section only output when there is an issue identified\\\n",
    "\"title\": \"{{A short title about the issue}}\", \\\n",
    "\"description\": \"{{A detail description about the issue}}\", \\\n",
    "\"photo_date\": \"{{Extracted photographic date from its metadata in yyyy-mm-dd:hh:mm:ss format. Leave it blank if no metadata found in it.}}\", \\\n",
    "\"longitude\": \"{{Extracted longitude of photographic location from its metadata. Do not make up any number. Output -1 if fails to extract location info from image}}\",\\\n",
    "\"latitude\": \"{{Extracted latitude of photographic location from its metadata. Do not make up any number. Output -1 if fails to extract location info from image}}\",\\\n",
    "\"category\": \"{{Identified category: 01-Infrastructure Damage, 02-Cleanliness, 03-Safety Hazards, 04-Duplicated}}\",\\\n",
    "\"priority\": \"{{Suggested Priority: 01-Very High, 02-High, 03-Medium, 04-Low}}\",\\\n",
    "\"suggested_action\": \"{{01-Immediate Attendance, 02-Schedule Inspection, 03-Schedule Service, 04-Refer to similar issue }}\"\\\n",
    "} \\\n",
    "\"\"\"\\\n",
    "'\n",
    "\n",
    "json_data = {\n",
    "    \"model\": model,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_msg},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.7,\n",
    "    \"do_sample\": \"True\" \n",
    "}\n",
    "\n",
    "response = requests.post(url=openai_chat_api_endpoint, headers=headers, json=json_data)\n",
    "print(\"Result:\", response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
